{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499ef26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b35234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/gygsnz5n09n9kvs6h09qf02m0000gn/T/ipykernel_90304/3082548048.py:1: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/Users/mamatharaj/Desktop/python/aws_review_sofware_dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/mamatharaj/Desktop/python/aws_review_sofware_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "841e386c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'overall', 'verified', 'reviewTime', 'reviewerID', 'asin',\n",
       "       'style', 'reviewerName', 'reviewText', 'summary', 'unixReviewTime',\n",
       "       'vote', 'image'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c245b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"words\"]=\"default value\"\n",
    "df[\"sentences\"]=\"default value\"\n",
    "\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    df.at[i,\"words\"]= list(\"\")\n",
    "    df.at[i,\"sentences\"] = list(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a19313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851671a",
   "metadata": {},
   "source": [
    "# Generating features from the review text data column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689b3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(499):\n",
    "    l1= sent_tokenize(df.loc[i,\"reviewText\"])\n",
    "    df.at[i,\"sentences\"]=l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ee95c",
   "metadata": {},
   "source": [
    "# Generating features using Sentence Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251bbed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 4.492929220199585 secs.\n"
     ]
    }
   ],
   "source": [
    "from pywsd.utils import lemmatize_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c6155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(df.shape[0]):\n",
    "    df.at[k,\"words\"]=list(\"\")\n",
    "    for j in range(len(df.loc[k,\"sentences\"])):\n",
    "        df.at[k,\"words\"].extend(lemmatize_sentence(df.loc[k,\"sentences\"][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd1eb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>words</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 11, 2014</td>\n",
       "      <td>A240ORQ2LF9LUI</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Michelle W</td>\n",
       "      <td>The materials arrived early and were in excell...</td>\n",
       "      <td>Material Great</td>\n",
       "      <td>1394496000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[the, material, arrive, early, and, be, in, ex...</td>\n",
       "      <td>[The materials arrived early and were in excel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 23, 2014</td>\n",
       "      <td>A1YCCU0YRLS0FE</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Rosalind White Ames</td>\n",
       "      <td>I am really enjoying this book with the worksh...</td>\n",
       "      <td>Health</td>\n",
       "      <td>1393113600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[i, be, really, enjoy, this, book, with, the, ...</td>\n",
       "      <td>[I am really enjoying this book with the works...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 17, 2014</td>\n",
       "      <td>A1BJHRQDYVAY2J</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Allan R. Baker</td>\n",
       "      <td>IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR ...</td>\n",
       "      <td>ARE YOU KIDING ME?</td>\n",
       "      <td>1392595200</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[if, you, be, take, this, class, don, '', t, w...</td>\n",
       "      <td>[IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 17, 2014</td>\n",
       "      <td>APRDVZ6QBIQXT</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>This book was missing pages!!! Important pages...</td>\n",
       "      <td>missing pages!!</td>\n",
       "      <td>1392595200</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[this, book, be, miss, page, !, !, !, importan...</td>\n",
       "      <td>[This book was missing pages!!!, Important pag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10 14, 2013</td>\n",
       "      <td>A2JZTTBSLS1QXV</td>\n",
       "      <td>0077775473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albert V.</td>\n",
       "      <td>I have used LearnSmart and can officially say ...</td>\n",
       "      <td>Best study product out there!</td>\n",
       "      <td>1381708800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[i, have, use, learnsmart, and, can, officiall...</td>\n",
       "      <td>[I have used LearnSmart and can officially say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0           0      4.0      True  03 11, 2014  A240ORQ2LF9LUI  0077613252   \n",
       "1           1      4.0      True  02 23, 2014  A1YCCU0YRLS0FE  0077613252   \n",
       "2           2      1.0      True  02 17, 2014  A1BJHRQDYVAY2J  0077613252   \n",
       "3           3      3.0      True  02 17, 2014   APRDVZ6QBIQXT  0077613252   \n",
       "4           4      5.0     False  10 14, 2013  A2JZTTBSLS1QXV  0077775473   \n",
       "\n",
       "                        style         reviewerName  \\\n",
       "0  {'Format:': ' Loose Leaf'}           Michelle W   \n",
       "1  {'Format:': ' Loose Leaf'}  Rosalind White Ames   \n",
       "2  {'Format:': ' Loose Leaf'}       Allan R. Baker   \n",
       "3  {'Format:': ' Loose Leaf'}                 Lucy   \n",
       "4                         NaN            Albert V.   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  The materials arrived early and were in excell...   \n",
       "1  I am really enjoying this book with the worksh...   \n",
       "2  IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR ...   \n",
       "3  This book was missing pages!!! Important pages...   \n",
       "4  I have used LearnSmart and can officially say ...   \n",
       "\n",
       "                         summary  unixReviewTime vote image  \\\n",
       "0                 Material Great      1394496000  NaN   NaN   \n",
       "1                         Health      1393113600  NaN   NaN   \n",
       "2             ARE YOU KIDING ME?      1392595200    7   NaN   \n",
       "3                missing pages!!      1392595200    3   NaN   \n",
       "4  Best study product out there!      1381708800  NaN   NaN   \n",
       "\n",
       "                                               words  \\\n",
       "0  [the, material, arrive, early, and, be, in, ex...   \n",
       "1  [i, be, really, enjoy, this, book, with, the, ...   \n",
       "2  [if, you, be, take, this, class, don, '', t, w...   \n",
       "3  [this, book, be, miss, page, !, !, !, importan...   \n",
       "4  [i, have, use, learnsmart, and, can, officiall...   \n",
       "\n",
       "                                           sentences  \n",
       "0  [The materials arrived early and were in excel...  \n",
       "1  [I am really enjoying this book with the works...  \n",
       "2  [IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR...  \n",
       "3  [This book was missing pages!!!, Important pag...  \n",
       "4  [I have used LearnSmart and can officially say...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bac2ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"words_sentences\"] = [' ' for i in range(459436)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55c8b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str(list1):\n",
    "    s1 = ''\n",
    "    for i1 in list1:\n",
    "        s1 = s1+' '+i1\n",
    "    return s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66cee673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "for k in range(df.shape[0]):\n",
    "    df.loc[k,\"words_sentences\"]=get_str(df.loc[k,\"words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d71bfb2",
   "metadata": {},
   "source": [
    "# Using Tfidf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "781dabb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84003012",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df.words_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92662d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = pd.DataFrame(tfidf_matrix.todense(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a29a222c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>0321670094</th>\n",
       "      <th>0321701801</th>\n",
       "      <th>0321719808</th>\n",
       "      <th>0789744449</th>\n",
       "      <th>0824831659</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.324845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00  000  0000  0321670094  0321701801  0321719808  0789744449  \\\n",
       "0  0.000000  0.0   0.0         0.0         0.0         0.0         0.0   \n",
       "1  0.000000  0.0   0.0         0.0         0.0         0.0         0.0   \n",
       "2  0.324845  0.0   0.0         0.0         0.0         0.0         0.0   \n",
       "3  0.000000  0.0   0.0         0.0         0.0         0.0         0.0   \n",
       "4  0.000000  0.0   0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   0824831659   10  100  ...  years  yellow  yes  yesterday   yo  young  \\\n",
       "0         0.0  0.0  0.0  ...    0.0     0.0  0.0        0.0  0.0    0.0   \n",
       "1         0.0  0.0  0.0  ...    0.0     0.0  0.0        0.0  0.0    0.0   \n",
       "2         0.0  0.0  0.0  ...    0.0     0.0  0.0        0.0  0.0    0.0   \n",
       "3         0.0  0.0  0.0  ...    0.0     0.0  0.0        0.0  0.0    0.0   \n",
       "4         0.0  0.0  0.0  ...    0.0     0.0  0.0        0.0  0.0    0.0   \n",
       "\n",
       "   youtube   yr  zero  zoom  \n",
       "0      0.0  0.0   0.0   0.0  \n",
       "1      0.0  0.0   0.0   0.0  \n",
       "2      0.0  0.0   0.0   0.0  \n",
       "3      0.0  0.0   0.0   0.0  \n",
       "4      0.0  0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3324 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99398218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y=df[\"verified\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f87e3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecd1aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "442a6eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_1=pd.DataFrame(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01379ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_enc=df_y_1.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21f15d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   verified\n",
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_enc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08283d9b",
   "metadata": {},
   "source": [
    "# Applying Classfication algorithms on generated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "848f5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd2f6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC=GradientBoostingClassifier(n_estimators=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b081555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mamatharaj/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "gb_c=GBC.fit(dense,df_y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC.score(dense,df_y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8471d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99f2cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecTree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08401e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_M=DecTree.fit(dense,df_y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf6359f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6735976283965558"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_M.score(dense,df_y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b356bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
